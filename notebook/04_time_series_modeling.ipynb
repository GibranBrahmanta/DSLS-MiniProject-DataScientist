{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pmdarima.arima import auto_arima\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "\n",
    "    def __init__(self, city, model_name, attr) -> None:\n",
    "        self.model_name = model_name\n",
    "        self.attr = attr\n",
    "        self.model = self.get_model(city, model_name, attr)\n",
    "    \n",
    "    def get_model(self, city, model_name, attr):\n",
    "        model = None\n",
    "        if model_name == 'ARIMA':\n",
    "            model = ARIMAForecast(city, attr)\n",
    "        return model\n",
    "    \n",
    "    def train(self, data):\n",
    "        self.model.train(data)\n",
    "    \n",
    "    def predict(self, street, data, timestep):\n",
    "        used_data = data.copy()\n",
    "        used_data.index = pd.DatetimeIndex(used_data['time'], freq='H')\n",
    "        used_data = used_data.drop(columns=['time'])\n",
    "        pred_res = self.model.predict(street=street, data=used_data, timestep=timestep)\n",
    "        return pred_res\n",
    "\n",
    "class ARIMAForecast:\n",
    "\n",
    "    param_path = \"../model/time_series/ARIMA_{}_{}.parquet.gzip\"\n",
    "\n",
    "    def __init__(self, city, attr):\n",
    "        try:\n",
    "            self.city = city\n",
    "            self.attr = attr\n",
    "            self.param = pd.read_parquet(self.param_path.format(city, attr))\n",
    "        except:\n",
    "            print(\"ARIMA model must be trained first\")\n",
    "    \n",
    "    def train(self, data):\n",
    "        lst_street = set(data['street'])\n",
    "\n",
    "        result = []\n",
    "        \n",
    "        for street in lst_street:\n",
    "            print(\"Train on {}\".format(street))\n",
    "            used_data = data[data['street'] == street].loc[:,['time', self.attr]]\n",
    "            used_data.index = pd.DatetimeIndex(used_data['time'], freq='H')\n",
    "            used_data = used_data.drop(columns=['time'])\n",
    "            arima_model = auto_arima(\n",
    "                used_data, start_p=1, d=0, start_q=1, test='adf',\n",
    "                max_p=6, max_d=5, max_q=6, m=1, seasonal=False,\n",
    "                start_P=0, D=0, trace=False, error_action='ignore',\n",
    "                suppress_warnings=False, stepwise=True\n",
    "            )\n",
    "            p, d, q = arima_model.get_params().get(\"order\")\n",
    "            result.append([\n",
    "                street,\n",
    "                p,\n",
    "                d,\n",
    "                q\n",
    "            ])\n",
    "        \n",
    "        result_df = pd.DataFrame(data=result, columns=['street', 'p', 'd', 'q'])\n",
    "        result_df.to_parquet(\n",
    "            self.param_path.format(self.city, self.attr),\n",
    "            index=False,\n",
    "            compression=\"gzip\"\n",
    "        )\n",
    "\n",
    "    def predict(self, street, data, timestep):\n",
    "        p, d, q = self.get_param(street)\n",
    "        model = ARIMA(data.values, order=(p,d,q))\n",
    "        model_fitted = model.fit()\n",
    "        res = model_fitted.forecast(steps=timestep)\n",
    "        return res\n",
    "\n",
    "    def get_param(self, street):\n",
    "        data = self.param[self.param['street'] == street]\n",
    "        return data['p'].values[0], data['d'].values[0], data['q'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_parquet(\"../data/processed/final_dataset_Bogor.parquet.gzip\")\n",
    "\n",
    "train_dataset = dataset[dataset['time_series_split'] == 'train']\n",
    "test_dataset = dataset[dataset['time_series_split'] == 'test']\n",
    "\n",
    "lst_street = list(set(train_dataset['street']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Predictor(\n",
    "    city='Bogor',\n",
    "    model_name='ARIMA',\n",
    "    attr='median_speed_kmh'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "street = 'Surya Kencana'\n",
    "\n",
    "used_train_data = train_dataset[train_dataset['street'] == street]\n",
    "used_test_data = test_dataset[test_dataset['street'] == street]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DSLS\\Mini Project\\Data Scientist\\.venv\\Lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_res = model.predict(\n",
    "    street=street,\n",
    "    data=used_train_data.loc[:,['time', 'median_speed_kmh']],\n",
    "    timestep=used_test_data.shape[0]\n",
    ")\n",
    "pred_res.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "858"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "286*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7589b95cb068f3d0e739a979a2e703391a2fe697c461cb856f6f0278f508a942"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
